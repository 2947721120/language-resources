# Cardinal numbers.
TOKENIZE_AND_CLASSIFY	1	tokens { cardinal { integer: "1" } }
TOKENIZE_AND_CLASSIFY	2	tokens { cardinal { integer: "2" } }
TOKENIZE_AND_CLASSIFY	3	tokens { cardinal { integer: "3" } }
TOKENIZE_AND_CLASSIFY	4	tokens { cardinal { integer: "4" } }
TOKENIZE_AND_CLASSIFY	5	tokens { cardinal { integer: "5" } }
TOKENIZE_AND_CLASSIFY	6	tokens { cardinal { integer: "6" } }
TOKENIZE_AND_CLASSIFY	7	tokens { cardinal { integer: "7" } }
TOKENIZE_AND_CLASSIFY	8	tokens { cardinal { integer: "8" } }
TOKENIZE_AND_CLASSIFY	9	tokens { cardinal { integer: "9" } }
TOKENIZE_AND_CLASSIFY	10	tokens { cardinal { integer: "10" } }
TOKENIZE_AND_CLASSIFY	747	tokens { cardinal { integer: "747" } }
# Decimals.
TOKENIZE_AND_CLASSIFY	367.78	tokens { decimal { integer_part: "367" fractional_part: "78" } }
TOKENIZE_AND_CLASSIFY	1.178	tokens { decimal { integer_part: "1" fractional_part: "178" } }
TOKENIZE_AND_CLASSIFY	3673333.8	tokens { decimal { integer_part: "3673333" fractional_part: "8" } }
# Digits.
TOKENIZE_AND_CLASSIFY	007	tokens { digit: "007" }
TOKENIZE_AND_CLASSIFY	008	tokens { digit: "008" }
TOKENIZE_AND_CLASSIFY	01	tokens { digit: "01" }
# Numbers with context.
TOKENIZE_AND_CLASSIFY	boeing 747	tokens { name: "boeing" } tokens { cardinal { integer: "747" } }
TOKENIZE_AND_CLASSIFY	A 380	tokens { name: "A" } tokens { cardinal { integer: "380" } }
# Telephone numbers.
TOKENIZE_AND_CLASSIFY	0701234567	tokens { telephone { number_part: "0701234567" } }
TOKENIZE_AND_CLASSIFY	+94 701234567	tokens { telephone { country_code: "94" number_part: "701234567" } }
TOKENIZE_AND_CLASSIFY	0701 234 567	tokens { telephone { number_part: "0701" number_part: "234" number_part: "567" } }
# Electronic.
TOKENIZE_AND_CLASSIFY	www.google.lk	tokens { electronic { domain: "www.google.lk" } }
TOKENIZE_AND_CLASSIFY	saman@gmail.com	tokens { electronic { username: "saman@" domain: "gmail.com" } }
# Fractions
TOKENIZE_AND_CLASSIFY	1/2	tokens { fraction { numerator: 1 denominator: 2 } }
TOKENIZE_AND_CLASSIFY	41/122	tokens { fraction { numerator: 41 denominator: 122 } }
# Test cases with Sinhala letters.
TOKENIZE_AND_CLASSIFY	කේෂාන් සංජය	tokens { name: "කේෂාන්" } tokens { name: "සංජය" }
TOKENIZE_AND_CLASSIFY	138 පාර	tokens { cardinal { integer: "138" } } tokens { name: "පාර" }
# LSEQs.
TOKENIZE_AND_CLASSIFY	FBI	tokens { letters: "FBI" }
TOKENIZE_AND_CLASSIFY	CIA	tokens { letters: "CIA" }
# Emoticons.
TOKENIZE_AND_CLASSIFY	:)	tokens { concept: ":)" }
TOKENIZE_AND_CLASSIFY	:-D	tokens { concept: ":-D" }
TOKENIZE_AND_CLASSIFY	:-O	tokens { concept: ":-O" }
TOKENIZE_AND_CLASSIFY	:-|	tokens { concept: ":-|" }
TOKENIZE_AND_CLASSIFY	:@	tokens { concept: ":@" }
# Verbitm and Spoken punct.
TOKENIZE_AND_CLASSIFY	I am @ home	tokens { name: "I" } tokens { name: "am" } tokens { verbatim: "@" } tokens { name: "home" }
TOKENIZE_AND_CLASSIFY	4++	tokens { cardinal { integer: "4" } } tokens { verbatim: "+" } tokens { verbatim: "+" }
TOKENIZE_AND_CLASSIFY	1.2.2	tokens { cardinal { integer: "1" } } tokens { verbatim: ".2.2" }
TOKENIZE_AND_CLASSIFY	done. thanks	tokens { name: "done" } tokens { name: "." pause_length: PAUSE_LONG phrase_break: true type: PUNCT } tokens { name: "thanks" }
TOKENIZE_AND_CLASSIFY	me & him	tokens { name: "me" } tokens { verbatim: "&" } tokens { name: "him" }
TOKENIZE_AND_CLASSIFY	මම ගෙදර. ඔබ කොහිද	tokens { name: "මම" } tokens { name: "ගෙදර" } tokens { name: "." pause_length: PAUSE_LONG phrase_break: true type: PUNCT } tokens { name: "ඔබ" } tokens { name: "කොහිද" }
TOKENIZE_AND_CLASSIFY	>	tokens { verbatim: ">" }
TOKENIZE_AND_CLASSIFY	<	tokens { verbatim: "<" }
